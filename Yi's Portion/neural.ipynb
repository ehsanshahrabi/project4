{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fertility rate_country</th>\n",
       "      <th>GDP per capita_country</th>\n",
       "      <th>Gini index_country</th>\n",
       "      <th>Unemployment_country</th>\n",
       "      <th>Total Permanent Residents</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>State</th>\n",
       "      <th>Population Count</th>\n",
       "      <th>Unemployeement Rate</th>\n",
       "      <th>per capita personal Income</th>\n",
       "      <th>Covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>551</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2005</td>\n",
       "      <td>1.76</td>\n",
       "      <td>42678.598137</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>19800</td>\n",
       "      <td>1.76</td>\n",
       "      <td>California</td>\n",
       "      <td>2593</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>38932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>559</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2006</td>\n",
       "      <td>1.82</td>\n",
       "      <td>43281.317979</td>\n",
       "      <td>35.9000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>17207</td>\n",
       "      <td>1.36</td>\n",
       "      <td>California</td>\n",
       "      <td>2526</td>\n",
       "      <td>0.049032</td>\n",
       "      <td>41746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2007</td>\n",
       "      <td>1.86</td>\n",
       "      <td>44046.503467</td>\n",
       "      <td>34.4000</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>14545</td>\n",
       "      <td>1.38</td>\n",
       "      <td>California</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>43385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>575</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.91</td>\n",
       "      <td>43633.753386</td>\n",
       "      <td>35.4000</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>14348</td>\n",
       "      <td>1.30</td>\n",
       "      <td>California</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>43567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.89</td>\n",
       "      <td>41351.692888</td>\n",
       "      <td>35.1000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>15748</td>\n",
       "      <td>1.39</td>\n",
       "      <td>California</td>\n",
       "      <td>2590</td>\n",
       "      <td>0.115317</td>\n",
       "      <td>41689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.92</td>\n",
       "      <td>42025.838804</td>\n",
       "      <td>33.7000</td>\n",
       "      <td>8.040000</td>\n",
       "      <td>12792</td>\n",
       "      <td>1.23</td>\n",
       "      <td>California</td>\n",
       "      <td>2364</td>\n",
       "      <td>0.124521</td>\n",
       "      <td>43246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.91</td>\n",
       "      <td>37260.671968</td>\n",
       "      <td>33.2000</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>11572</td>\n",
       "      <td>1.09</td>\n",
       "      <td>California</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>45557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.92</td>\n",
       "      <td>38332.481509</td>\n",
       "      <td>33.1000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>12014</td>\n",
       "      <td>1.16</td>\n",
       "      <td>California</td>\n",
       "      <td>2090</td>\n",
       "      <td>0.105218</td>\n",
       "      <td>48121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.83</td>\n",
       "      <td>39975.190299</td>\n",
       "      <td>32.7000</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>12984</td>\n",
       "      <td>1.31</td>\n",
       "      <td>California</td>\n",
       "      <td>2215</td>\n",
       "      <td>0.090285</td>\n",
       "      <td>48502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>623</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.81</td>\n",
       "      <td>41285.064398</td>\n",
       "      <td>33.1000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>12225</td>\n",
       "      <td>1.20</td>\n",
       "      <td>California</td>\n",
       "      <td>2261</td>\n",
       "      <td>0.075615</td>\n",
       "      <td>51266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>631</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.80</td>\n",
       "      <td>42597.682956</td>\n",
       "      <td>33.3000</td>\n",
       "      <td>4.810000</td>\n",
       "      <td>12592</td>\n",
       "      <td>1.20</td>\n",
       "      <td>California</td>\n",
       "      <td>2694</td>\n",
       "      <td>0.062433</td>\n",
       "      <td>54546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>639</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.79</td>\n",
       "      <td>44255.112068</td>\n",
       "      <td>33.1000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>12673</td>\n",
       "      <td>1.07</td>\n",
       "      <td>California</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.055160</td>\n",
       "      <td>56560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.74</td>\n",
       "      <td>46104.055397</td>\n",
       "      <td>32.6000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10948</td>\n",
       "      <td>0.97</td>\n",
       "      <td>California</td>\n",
       "      <td>2123</td>\n",
       "      <td>0.048373</td>\n",
       "      <td>58804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.68</td>\n",
       "      <td>47202.199606</td>\n",
       "      <td>33.7000</td>\n",
       "      <td>3.740000</td>\n",
       "      <td>9908</td>\n",
       "      <td>0.90</td>\n",
       "      <td>California</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>61508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>663</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.63</td>\n",
       "      <td>49288.693112</td>\n",
       "      <td>32.8000</td>\n",
       "      <td>5.949286</td>\n",
       "      <td>11337</td>\n",
       "      <td>1.10</td>\n",
       "      <td>California</td>\n",
       "      <td>2149</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>64919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>671</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.56</td>\n",
       "      <td>45872.027289</td>\n",
       "      <td>32.6000</td>\n",
       "      <td>5.949286</td>\n",
       "      <td>9655</td>\n",
       "      <td>1.36</td>\n",
       "      <td>California</td>\n",
       "      <td>1872</td>\n",
       "      <td>0.101459</td>\n",
       "      <td>70643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.56</td>\n",
       "      <td>50056.266291</td>\n",
       "      <td>33.7625</td>\n",
       "      <td>5.949286</td>\n",
       "      <td>9229</td>\n",
       "      <td>1.25</td>\n",
       "      <td>California</td>\n",
       "      <td>1651</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>76800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    Country Name  Year  Fertility rate_country  \\\n",
       "551         551  United Kingdom  2005                    1.76   \n",
       "559         559  United Kingdom  2006                    1.82   \n",
       "567         567  United Kingdom  2007                    1.86   \n",
       "575         575  United Kingdom  2008                    1.91   \n",
       "583         583  United Kingdom  2009                    1.89   \n",
       "591         591  United Kingdom  2010                    1.92   \n",
       "599         599  United Kingdom  2011                    1.91   \n",
       "607         607  United Kingdom  2012                    1.92   \n",
       "615         615  United Kingdom  2013                    1.83   \n",
       "623         623  United Kingdom  2014                    1.81   \n",
       "631         631  United Kingdom  2015                    1.80   \n",
       "639         639  United Kingdom  2016                    1.79   \n",
       "647         647  United Kingdom  2017                    1.74   \n",
       "655         655  United Kingdom  2018                    1.68   \n",
       "663         663  United Kingdom  2019                    1.63   \n",
       "671         671  United Kingdom  2020                    1.56   \n",
       "679         679  United Kingdom  2021                    1.56   \n",
       "\n",
       "     GDP per capita_country  Gini index_country  Unemployment_country  \\\n",
       "551            42678.598137             35.5000              5.350000   \n",
       "559            43281.317979             35.9000              5.260000   \n",
       "567            44046.503467             34.4000              5.620000   \n",
       "575            43633.753386             35.4000              7.540000   \n",
       "583            41351.692888             35.1000              7.790000   \n",
       "591            42025.838804             33.7000              8.040000   \n",
       "599            37260.671968             33.2000              7.880000   \n",
       "607            38332.481509             33.1000              7.520000   \n",
       "615            39975.190299             32.7000              6.110000   \n",
       "623            41285.064398             33.1000              5.300000   \n",
       "631            42597.682956             33.3000              4.810000   \n",
       "639            44255.112068             33.1000              4.330000   \n",
       "647            46104.055397             32.6000              4.000000   \n",
       "655            47202.199606             33.7000              3.740000   \n",
       "663            49288.693112             32.8000              5.949286   \n",
       "671            45872.027289             32.6000              5.949286   \n",
       "679            50056.266291             33.7625              5.949286   \n",
       "\n",
       "     Total Permanent Residents  Percentage       State  Population Count  \\\n",
       "551                      19800        1.76  California              2593   \n",
       "559                      17207        1.36  California              2526   \n",
       "567                      14545        1.38  California              2488   \n",
       "575                      14348        1.30  California              2347   \n",
       "583                      15748        1.39  California              2590   \n",
       "591                      12792        1.23  California              2364   \n",
       "599                      11572        1.09  California              2016   \n",
       "607                      12014        1.16  California              2090   \n",
       "615                      12984        1.31  California              2215   \n",
       "623                      12225        1.20  California              2261   \n",
       "631                      12592        1.20  California              2694   \n",
       "639                      12673        1.07  California              2379   \n",
       "647                      10948        0.97  California              2123   \n",
       "655                       9908        0.90  California              2025   \n",
       "663                      11337        1.10  California              2149   \n",
       "671                       9655        1.36  California              1872   \n",
       "679                       9229        1.25  California              1651   \n",
       "\n",
       "     Unemployeement Rate  per capita personal Income  Covid  \n",
       "551             0.053783                       38932      0  \n",
       "559             0.049032                       41746      0  \n",
       "567             0.053217                       43385      0  \n",
       "575             0.073101                       43567      0  \n",
       "583             0.115317                       41689      0  \n",
       "591             0.124521                       43246      0  \n",
       "599             0.118818                       45557      0  \n",
       "607             0.105218                       48121      0  \n",
       "615             0.090285                       48502      0  \n",
       "623             0.075615                       51266      0  \n",
       "631             0.062433                       54546      0  \n",
       "639             0.055160                       56560      0  \n",
       "647             0.048373                       58804      0  \n",
       "655             0.042579                       61508      0  \n",
       "663             0.040935                       64919      0  \n",
       "671             0.101459                       70643      1  \n",
       "679             0.073200                       76800      1  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset, and use United Kingdom - California as an example\n",
    "data = pd.read_csv('sample.csv')\n",
    "data = data[data[\"Country Name\"]== \"United Kingdom\"]\n",
    "data = data[data[\"State\"]==\"California\"]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the test data\n",
    "new_data = data[data['Year'] == 2019]\n",
    "data = data[data['Year'] < 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features (input) and target variable (output)\n",
    "X = data[['Fertility rate_country', 'GDP per capita_country', 'Gini index_country', 'Unemployment_country', 'Unemployeement Rate', 'per capita personal Income']].values\n",
    "y = data[['Population Count']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the input features using StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the target variable using StandardScaler\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step - loss: 0.9100 - val_loss: 1.7163\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8798 - val_loss: 1.7155\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8508 - val_loss: 1.7156\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8231 - val_loss: 1.7167\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7966 - val_loss: 1.7186\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7713 - val_loss: 1.7213\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7470 - val_loss: 1.7249\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7236 - val_loss: 1.7294\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7009 - val_loss: 1.7346\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6788 - val_loss: 1.7403\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6572 - val_loss: 1.7462\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6359 - val_loss: 1.7523\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6151 - val_loss: 1.7584\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5945 - val_loss: 1.7645\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5743 - val_loss: 1.7705\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5545 - val_loss: 1.7763\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5349 - val_loss: 1.7820\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5155 - val_loss: 1.7873\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4963 - val_loss: 1.7924\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4774 - val_loss: 1.7973\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4588 - val_loss: 1.8019\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4406 - val_loss: 1.8063\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4225 - val_loss: 1.8105\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4047 - val_loss: 1.8144\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3871 - val_loss: 1.8182\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3696 - val_loss: 1.8218\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3524 - val_loss: 1.8253\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3355 - val_loss: 1.8287\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3188 - val_loss: 1.8320\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3023 - val_loss: 1.8352\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2861 - val_loss: 1.8384\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2701 - val_loss: 1.8415\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2546 - val_loss: 1.8445\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2393 - val_loss: 1.8476\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2244 - val_loss: 1.8510\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2100 - val_loss: 1.8545\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1960 - val_loss: 1.8580\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1825 - val_loss: 1.8617\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1696 - val_loss: 1.8657\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - val_loss: 1.8701\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1451 - val_loss: 1.8749\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1336 - val_loss: 1.8800\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1226 - val_loss: 1.8853\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1122 - val_loss: 1.8907\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1024 - val_loss: 1.8963\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0932 - val_loss: 1.9021\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0846 - val_loss: 1.9081\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0766 - val_loss: 1.9141\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0692 - val_loss: 1.9204\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0625 - val_loss: 1.9267\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0564 - val_loss: 1.9333\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0508 - val_loss: 1.9401\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0458 - val_loss: 1.9470\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0413 - val_loss: 1.9539\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0374 - val_loss: 1.9608\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0338 - val_loss: 1.9673\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0307 - val_loss: 1.9736\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0280 - val_loss: 1.9795\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 1.9850\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 1.9898\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 1.9939\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0206 - val_loss: 1.9975\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 2.0002\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 2.0023\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 2.0035\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0166 - val_loss: 2.0038\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 2.0034\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 2.0021\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 2.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 1.9972\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 1.9939\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 1.9900\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 1.9854\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 1.9803\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 1.9748\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 1.9689\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 1.9626\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 1.9561\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 1.9493\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 1.9423\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 1.9351\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 1.9278\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 1.9198\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 1.9118\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 1.9039\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 1.8960\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 1.8885\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 1.8811\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 1.8739\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 1.8670\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - val_loss: 1.8604\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 1.8544\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0035 - val_loss: 1.8488\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 1.8437\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - val_loss: 1.8391\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - val_loss: 1.8350\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 1.8311\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 1.8275\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 1.8242\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 1.8213\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='sigmoid'),\n",
    "    keras.layers.Dense(1)  # Output layer with 1 node for the predicted Total Permanent Residents\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # Mean Squared Error loss\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform the scaled predictions to get the actual predicted Total Permanent Residents values\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Accuracy Percentage: 24.34%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the Mean Squared Error (MSE) between predicted and true values\n",
    "mse = mean_squared_error(y_test, y_pred_actual)\n",
    "\n",
    "# Calculate the variance of the true values\n",
    "variance_true_values = np.var(y_test)\n",
    "\n",
    "# Calculate the Percentage Accuracy\n",
    "percentage_accuracy = 100 * (1 - (mse / variance_true_values))\n",
    "\n",
    "# Display the Percentage Accuracy\n",
    "print(\"MSE Accuracy Percentage: {:.2f}%\".format(percentage_accuracy))\n",
    "\n",
    "\n",
    "X_new = new_data[['Fertility rate_country', 'GDP per capita_country', 'Gini index_country', 'Unemployment_country', 'Unemployeement Rate', 'per capita personal Income']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 88.44873046875\n",
      "Mean Absolute Percentage Error (MAPE): 3.6511387887578928\n",
      "Mean Squared Error (MSE): 14287.37979833285\n",
      "Root Mean Squared Error (RMSE): 119.52982806953605\n",
      "Coefficient of Variation of Root Mean Squared Error (CVRMSE): 4.957686771859645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_actual)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = np.mean(np.abs((y_test - y_pred_actual) / y_test)) * 100\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_actual)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate Coefficient of Variation of Root Mean Squared Error (CVRMSE)\n",
    "cvrmse = (rmse / np.mean(y_test)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Coefficient of Variation of Root Mean Squared Error (CVRMSE):\", cvrmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "# Normalize the input features using StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "X_new_scaled = scaler_X.fit_transform(X_new)\n",
    "\n",
    "# Make predictions row by row\n",
    "predictions = []\n",
    "for i in range(X_new_scaled.shape[0]):\n",
    "    input_row = X_new_scaled[i].reshape(1, -1)  # Reshape to 2D array for prediction\n",
    "    prediction_scaled = model.predict(input_row)\n",
    "    prediction_actual = scaler_y.inverse_transform(prediction_scaled)  # Inverse-transform to get actual values\n",
    "    predictions.append(prediction_actual[0][0])  # Assuming the output is a single value (Total Permanent Residents)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Population Count</th>\n",
       "      <th>Predicted_Total_Permanent_Residents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>California</td>\n",
       "      <td>2149</td>\n",
       "      <td>2364.099121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Country Name       State  Population Count  \\\n",
       "0  2019  United Kingdom  California              2149   \n",
       "\n",
       "   Predicted_Total_Permanent_Residents  \n",
       "0                          2364.099121  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame with the predictions\n",
    "predictions_df = pd.DataFrame({'Predicted_Total_Permanent_Residents': predictions})\n",
    "\n",
    "new_data = new_data.reset_index()\n",
    "\n",
    "# Merge the predicted_data DataFrame with the original new_data DataFrame\n",
    "new_data_with_predictions = pd.merge(new_data[['Year', 'Country Name', 'State', 'Population Count']], predictions_df, left_index=True, right_index=True)\n",
    "\n",
    "# Concatenate the new DataFrame with the original new data\n",
    "new_data_with_predictions.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
